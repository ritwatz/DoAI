{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UUzoYUtf1_Fz",
        "outputId": "3d6480f3-41a5-46bf-a410-7116a0cf199b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        CRIM    ZN  INDUS CHAS    NOX     RM   AGE     DIS RAD    TAX  \\\n",
            "0    0.00632  18.0   2.31    0  0.538  6.575  65.2  4.0900   1  296.0   \n",
            "1    0.02731   0.0   7.07    0  0.469  6.421  78.9  4.9671   2  242.0   \n",
            "2    0.02729   0.0   7.07    0  0.469  7.185  61.1  4.9671   2  242.0   \n",
            "3    0.03237   0.0   2.18    0  0.458  6.998  45.8  6.0622   3  222.0   \n",
            "4    0.06905   0.0   2.18    0  0.458  7.147  54.2  6.0622   3  222.0   \n",
            "..       ...   ...    ...  ...    ...    ...   ...     ...  ..    ...   \n",
            "501  0.06263   0.0  11.93    0  0.573  6.593  69.1  2.4786   1  273.0   \n",
            "502  0.04527   0.0  11.93    0  0.573  6.120  76.7  2.2875   1  273.0   \n",
            "503  0.06076   0.0  11.93    0  0.573  6.976  91.0  2.1675   1  273.0   \n",
            "504  0.10959   0.0  11.93    0  0.573  6.794  89.3  2.3889   1  273.0   \n",
            "505  0.04741   0.0  11.93    0  0.573  6.030  80.8  2.5050   1  273.0   \n",
            "\n",
            "     PTRATIO       B  LSTAT  \n",
            "0       15.3  396.90   4.98  \n",
            "1       17.8  396.90   9.14  \n",
            "2       17.8  392.83   4.03  \n",
            "3       18.7  394.63   2.94  \n",
            "4       18.7  396.90   5.33  \n",
            "..       ...     ...    ...  \n",
            "501     21.0  391.99   9.67  \n",
            "502     21.0  396.90   9.08  \n",
            "503     21.0  396.90   5.64  \n",
            "504     21.0  393.45   6.48  \n",
            "505     21.0  396.90   7.88  \n",
            "\n",
            "[506 rows x 13 columns]\n",
            "0      24.0\n",
            "1      21.6\n",
            "2      34.7\n",
            "3      33.4\n",
            "4      36.2\n",
            "       ... \n",
            "501    22.4\n",
            "502    20.6\n",
            "503    23.9\n",
            "504    22.0\n",
            "505    11.9\n",
            "Name: MEDV, Length: 506, dtype: float64\n",
            "Mean Squared Error: 24.291119474973478\n",
            "Least Mean Squared Error: 24.291119474973478\n",
            "R-squared: 0.6687594935356326\n",
            "Least Mean Squared Error: 21.641412753226312\n",
            "Training R-squared: 0.7508856358979673\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ],
      "source": [
        "#Linear Regression\n",
        "# Step 1: Data Preparation\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the Boston Housing dataset\n",
        "boston = fetch_openml(data_id=531)\n",
        "\n",
        "X = boston.data\n",
        "y = boston.target\n",
        "\n",
        "print(X)\n",
        "print(y)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "# Convert pandas DataFrames and Series to NumPy arrays\n",
        "X_train = X_train.values\n",
        "X_test = X_test.values\n",
        "y_train = y_train.values\n",
        "y_test = y_test.values\n",
        "\n",
        "\n",
        "# Step 2: Model Selection and Training\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Initialize and train the linear regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Step 3: Model Evaluation\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Predict on the testing set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate mean squared error\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "\n",
        "# Calculate the least mean squared error achieved by the model\n",
        "lmse = np.min(mse)\n",
        "\n",
        "print(\"Mean Squared Error:\", mse)\n",
        "print(\"Least Mean Squared Error:\", lmse)\n",
        "\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(\"R-squared:\", r2)\n",
        "\n",
        "# Step 4: Generalization Check\n",
        "# Evaluate model performance on training data\n",
        "y_train_pred = model.predict(X_train)\n",
        "train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "train_r2 = r2_score(y_train, y_train_pred)\n",
        "\n",
        "print(\"Least Mean Squared Error:\", train_mse)\n",
        "print(\"Training R-squared:\", train_r2)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M7iLsZzj3fd2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}